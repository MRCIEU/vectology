{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os \n",
    "import gzip\n",
    "import timeit\n",
    "\n",
    "from scripts.vectology_functions import create_aaa_distances, create_pair_distances, embed_text, encode_traits, create_efo_nxo\n",
    "\n",
    "\n",
    "#!pip install pandas-profiling[notebook]==2.10.1\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "#from ontoma import OnToma\n",
    "#otmap = OnToma()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Apply the default theme\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "ebi_data = 'data/UK_Biobank_master_file.tsv'\n",
    "#efo_nodes = 'data/efo-nodes.tsv'\n",
    "#efo_data = 'data/efo_data.txt.gz'\n",
    "efo_nodes = 'data/epigraphdb_efo_nodes.csv'\n",
    "efo_rels = 'data/epigraphdb_efo_rels.csv'\n",
    "nxontology_measure = 'batet'\n",
    "\n",
    "modelData = [\n",
    "    {'name':'BioSentVec','model':'BioSentVec'},\n",
    "    {'name':'BioBERT','model':'biobert_v1.1_pubmed'},\n",
    "    {'name':'BlueBERT','model':'NCBI_BERT_pubmed_mimic_uncased_L-12_H-768_A-12'},\n",
    "    {'name':'GUSE','model':'GUSEv4'},\n",
    "    {'name':'BERT-EFO','model':'BERT-EFO'},\n",
    "    {'name':'Zooma','model':'Zooma'}\n",
    "]\n",
    "\n",
    "pallete=\"hls\"\n",
    "output='output/trait-efo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                      query       MAPPED_TERM_LABEL  \\\n0           Vascular disorders of intestine        vascular disease   \n1                              Gonarthrosis  osteoarthritis || knee   \n2  Psoriatic and enteropathic arthropathies     psoriatic arthritis   \n3          Pain associated with micturition                 dysuria   \n4                                Other mood           mood disorder   \n\n            MAPPED_TERM_URI MAPPING_TYPE  \n0  EFO_0004264, EFO_0009431        Broad  \n1               EFO_0004616        Broad  \n2               EFO_0003778      ? Broad  \n3               EFO_0003901      ? Broad  \n4               EFO_0004247      ? Broad  \n(1565, 4)\n(1613, 4)\n(1599, 4)\n                                      query       MAPPED_TERM_LABEL  \\\n0           Vascular disorders of intestine        vascular disease   \n1           Vascular disorders of intestine        vascular disease   \n2                              Gonarthrosis  osteoarthritis || knee   \n3  Psoriatic and enteropathic arthropathies     psoriatic arthritis   \n4          Pain associated with micturition                 dysuria   \n\n  MAPPING_TYPE           id  \n0        Broad  EFO_0004264  \n1        Broad  EFO_0009431  \n2        Broad  EFO_0004616  \n3      ? Broad  EFO_0003778  \n4      ? Broad  EFO_0003901  \n(1599, 4)\n(1323, 4)\nExact       685\nBroad       574\nNarrow       50\n?             7\n? Broad       3\n? Narrow      2\nNarrow?       1\n? Exact       1\nName: MAPPING_TYPE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get the EBI UKB data\n",
    "#get ebi data\n",
    "#url='https://raw.githubusercontent.com/EBISPOT/EFO-UKB-mappings/master/UK_Biobank_master_file.tsv'\n",
    "#ebi_df = pd.read_csv(url,sep='\\t')\n",
    "\n",
    "ebi_df = pd.read_csv(ebi_data,sep='\\t')\n",
    "\n",
    "#drop some columns\n",
    "ebi_df = ebi_df[['ZOOMA QUERY','MAPPED_TERM_LABEL','MAPPED_TERM_URI','MAPPING_TYPE']]\n",
    "ebi_df.rename(columns={'ZOOMA QUERY':'query'},inplace=True)\n",
    "print(ebi_df.head())\n",
    "print(ebi_df.shape)\n",
    "\n",
    "#create new rows for multiple labels\n",
    "#ebi_df = (\n",
    "#        ebi_df.assign(label=ebi_df.MAPPED_TERM_LABEL.str.split(\"\\|\\|\"))\n",
    "#        .explode(\"label\")\n",
    "#        .reset_index(drop=True).drop('MAPPED_TERM_LABEL',axis=1)\n",
    "#    )\n",
    "\n",
    "#create new rows for multiple ids\n",
    "ebi_df['MAPPED_TERM_URI']=ebi_df['MAPPED_TERM_URI'].str.replace('\\|\\|',',')\n",
    "ebi_df['MAPPED_TERM_URI']=ebi_df['MAPPED_TERM_URI'].str.replace('\\|',',')\n",
    "ebi_df = (\n",
    "        ebi_df.assign(id=ebi_df.MAPPED_TERM_URI.str.split(\",\"))\n",
    "        .explode(\"id\")\n",
    "        .reset_index(drop=True).drop('MAPPED_TERM_URI',axis=1)\n",
    "    )\n",
    "\n",
    "#clean up\n",
    "ebi_df['id'] = ebi_df['id'].str.strip()\n",
    "\n",
    "#drop where query and id are duplicates\n",
    "ebi_df.drop_duplicates(subset=['query','id'],inplace=True)\n",
    "print(ebi_df.shape)\n",
    "\n",
    "#drop nan\n",
    "ebi_df.dropna(inplace=True)\n",
    "print(ebi_df.shape)\n",
    "print(ebi_df.head())\n",
    "\n",
    "#drop cases where query and matched text are identical\n",
    "print(ebi_df.shape)\n",
    "ebi_df=ebi_df[ebi_df['query'].str.lower()!=ebi_df['MAPPED_TERM_LABEL'].str.lower()]\n",
    "print(ebi_df.shape)\n",
    "\n",
    "# get counts of mapping type\n",
    "print(ebi_df['MAPPING_TYPE'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                      efo_label  \\\n0                 Xeroderma pigmentosum variant   \n1                         Xeroderma pigmentosum   \n2                               Ischemic stroke   \n3                             Cerebral ischemia   \n4                          small cell carcinoma   \n...                                         ...   \n25385         Acetazolamide-responsive myotonia   \n25386  Complete androgen insensitivity syndrome   \n25387                Intermediate DEND syndrome   \n25388                              Epiblepharon   \n25389              Congenital eyelid retraction   \n\n                                          efo_id  \n0       http://www.orpha.net/ORDO/Orphanet_90342  \n1         http://www.orpha.net/ORDO/Orphanet_910  \n2      http://purl.obolibrary.org/obo/HP_0002140  \n3      http://purl.obolibrary.org/obo/HP_0002637  \n4           http://www.ebi.ac.uk/efo/EFO_0008524  \n...                                          ...  \n25385   http://www.orpha.net/ORDO/Orphanet_99736  \n25386   http://www.orpha.net/ORDO/Orphanet_99429  \n25387   http://www.orpha.net/ORDO/Orphanet_99989  \n25388   http://www.orpha.net/ORDO/Orphanet_99169  \n25389   http://www.orpha.net/ORDO/Orphanet_99176  \n\n[25390 rows x 2 columns]\nCPU times: user 58.1 ms, sys: 9.96 ms, total: 68.1 ms\nWall time: 67.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# get EFO node data\n",
    "efo_node_df = pd.read_csv(efo_nodes)\n",
    "efo_node_df.rename(columns={'efo.value':'efo_label','efo.id':'efo_id'},inplace=True)\n",
    "#drop type\n",
    "efo_node_df.drop('efo.type',inplace=True,axis=1)\n",
    "efo_node_df.drop_duplicates(inplace=True)\n",
    "print(efo_node_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Missing: 20\n(1323, 4)\n                                      query       MAPPED_TERM_LABEL  \\\n0           Vascular disorders of intestine        vascular disease   \n1           Vascular disorders of intestine        vascular disease   \n2                              Gonarthrosis  osteoarthritis || knee   \n3  Psoriatic and enteropathic arthropathies     psoriatic arthritis   \n4          Pain associated with micturition                 dysuria   \n\n  MAPPING_TYPE           id                               full_id  \n0        Broad  EFO_0004264  http://www.ebi.ac.uk/efo/EFO_0004264  \n1        Broad  EFO_0009431  http://www.ebi.ac.uk/efo/EFO_0009431  \n2        Broad  EFO_0004616  http://www.ebi.ac.uk/efo/EFO_0004616  \n3      ? Broad  EFO_0003778  http://www.ebi.ac.uk/efo/EFO_0003778  \n4      ? Broad  EFO_0003901  http://www.ebi.ac.uk/efo/EFO_0003901  \n(1303, 5)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#check all terms in EBI data set are in EFO node data\n",
    "efo_node_ids = list(efo_node_df['efo_id'])\n",
    "ebi_ids = list(ebi_df['id'])\n",
    "missing=[]\n",
    "matched = []\n",
    "for i in ebi_ids:\n",
    "    match = False\n",
    "    for s in efo_node_ids:\n",
    "        if i in s and match == False:\n",
    "            matched.append(s)\n",
    "            match = True\n",
    "    if match == False:\n",
    "        missing.append(i)\n",
    "print('Missing:',len(missing))\n",
    "\n",
    "# remove missing from ukb data\n",
    "print(ebi_df.shape)\n",
    "for i in missing:\n",
    "    ebi_df = ebi_df.drop(ebi_df[ebi_df['id'].str.contains(i)].index)\n",
    "ebi_df['full_id'] = matched\n",
    "print(ebi_df.head())\n",
    "print(ebi_df.shape)\n",
    "ebi_df.to_csv('output/ebi-ukb-cleaned.tsv',index=False,sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "# doesn't really need doing\n",
    "def preprocess():\n",
    "    process_text=[]\n",
    "    for k,g in ebi_df.groupby(np.arange(len(ebi_df))//20):\n",
    "        params={'text_list':list(g['query'])}\n",
    "        process_res = requests.post('http://vectology-api.mrcieu.ac.uk/preprocess',data=json.dumps(params))\n",
    "        process_text.extend([d['result'].replace('unspecified','').replace('nec','') for d in process_res.json()])\n",
    "    print(len(process_text))\n",
    "        \n",
    "    ebi_df.loc[:, 'processed'] = process_text\n",
    "    print(ebi_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BioSentVec done\n",
      "Encoding EBI queriues with biobert_v1.1_pubmed\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "Results 1303\n",
      "Encoding EBI queriues with NCBI_BERT_pubmed_mimic_uncased_L-12_H-768_A-12\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "Results 1303\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# encode the EBI query terms with Vectology models\n",
    "queries = list(ebi_df['query'])\n",
    "chunk=10\n",
    "\n",
    "vectology_models = ['BioSentVec','BioBERT','BlueBERT']\n",
    "\n",
    "for m in modelData:\n",
    "    name = m['name']\n",
    "    model = m['model']\n",
    "    if name in vectology_models: \n",
    "        f = f\"output/{m['name']}-ebi-encode.npy\"\n",
    "        if os.path.exists(f):\n",
    "            print(name,'done')\n",
    "        else:\n",
    "            print('Encoding EBI queriues with',model)\n",
    "            results=[]\n",
    "            for i in range(0,len(queries),chunk):\n",
    "                if i % 100 == 0:\n",
    "                    print(i)\n",
    "                batch = queries[i:i+chunk]\n",
    "                #print('\\n',i,queries[i:i+chunk])\n",
    "                res = embed_text(textList=batch,model=model)\n",
    "                for r in res:\n",
    "                    results.append(r)\n",
    "            print('Results',len(results))\n",
    "            np.save(f,results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BioSentVec done\nBioBERT done\nBlueBERT done\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# encode the EFO query terms with Vectology models\n",
    "queries = list(efo_node_df['efo_label'])\n",
    "chunk=20\n",
    "\n",
    "vectology_models = ['BioSentVec','BioBERT','BlueBERT']\n",
    "\n",
    "for m in modelData:\n",
    "    name = m['name']\n",
    "    model = m['model']\n",
    "    if name in vectology_models: \n",
    "        f = f\"output/{m['name']}-efo-encode.npy\"\n",
    "        if os.path.exists(f):\n",
    "            print(name,'done')\n",
    "        else:\n",
    "            print('Encoding EFO queriues with',model)\n",
    "            results=[]\n",
    "            for i in range(0,len(queries),chunk):\n",
    "                if i % 100 == 0:\n",
    "                    print(i)\n",
    "                batch = queries[i:i+chunk]\n",
    "                #print('\\n',i,queries[i:i+chunk])\n",
    "                res = embed_text(textList=batch,model=model_name)\n",
    "                for r in res:\n",
    "                    results.append(r)\n",
    "            print('Results',len(results))\n",
    "            np.save(f,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\nWall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Google Universal Sentence Encoder\n",
    "\n",
    "#!pip install  \"tensorflow>=2.0.0\"\n",
    "#!pip install  --upgrade tensorflow-hub\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 8.11 µs\n",
      "                                      query       MAPPED_TERM_LABEL  \\\n",
      "0           Vascular disorders of intestine        vascular disease   \n",
      "1           Vascular disorders of intestine        vascular disease   \n",
      "2                              Gonarthrosis  osteoarthritis || knee   \n",
      "3  Psoriatic and enteropathic arthropathies     psoriatic arthritis   \n",
      "4          Pain associated with micturition                 dysuria   \n",
      "\n",
      "  MAPPING_TYPE           id                               full_id  \n",
      "0        Broad  EFO_0004264  http://www.ebi.ac.uk/efo/EFO_0004264  \n",
      "1        Broad  EFO_0009431  http://www.ebi.ac.uk/efo/EFO_0009431  \n",
      "2        Broad  EFO_0004616  http://www.ebi.ac.uk/efo/EFO_0004616  \n",
      "3      ? Broad  EFO_0003778  http://www.ebi.ac.uk/efo/EFO_0003778  \n",
      "4      ? Broad  EFO_0003901  http://www.ebi.ac.uk/efo/EFO_0003901  \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create GUSE encodings for EBI and EFO\n",
    "\n",
    "guse_ebi_embeddings = embed(ebi_df['query'])\n",
    "guse_efo_embeddings = embed(efo_node_df['efo_label'])\n",
    "\n",
    "guse_ebi_embeddings_list = []\n",
    "for g in guse_ebi_embeddings:\n",
    "    guse_ebi_embeddings_list.append(g.numpy())\n",
    "np.save('output/GUSE-ebi-encode.npy',guse_ebi_embeddings_list)\n",
    "#ebi_df['GUSE']=guse_ebi_embeddings_list\n",
    "\n",
    "guse_efo_embeddings_list = []\n",
    "for g in guse_efo_embeddings:\n",
    "    guse_efo_embeddings_list.append(g.numpy())\n",
    "np.save('output/GUSE-efo-encode.npy',guse_efo_embeddings_list)\n",
    "#efo_df['GUSE']=guse_efo_embeddings_list\n",
    "\n",
    "print(ebi_df.head())\n",
    "\n",
    "#print(len(guse_ebi_embeddings), guse_ebi_embeddings[0].numpy())\n",
    "#print(len(guse_efo_embeddings), guse_efo_embeddings[0].numpy().shape)\n",
    "#guse_corr = np.inner(guse_ebi_embeddings, guse_efo_embeddings)\n",
    "\n",
    "#print(len(corr[0]))\n",
    "#np.save('output/guse-dd.npy',guse_corr)\n",
    "#a=np.load('output/guse-dd.npy')\n",
    "#print(len(a))\n",
    "\n",
    "# add to ebi_df\n",
    "#ebi_df['guse']=guse_ebi_embeddings\n",
    "#print(ebi_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#create nxontology network of EFO relationships\n",
    "efo_rel_df=pd.read_csv(efo_rels)\n",
    "efo_nx = create_efo_nxo(df=efo_rel_df,child_col='efo.id',parent_col='parent_efo.id')\n",
    "efo_nx.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pairs(model):\n",
    "    dd_name = f\"{output}/{model}-dd.npy\"\n",
    "    \n",
    "    v1 = list(ebi_df[model])\n",
    "    v2 = list(efo_df[model])\n",
    "    \n",
    "    if os.path.exists(dd_name):\n",
    "        print(dd_name,'already created, loading...')\n",
    "        with open(dd_name, 'rb') as f:\n",
    "            dd = np.load(f)\n",
    "    else:    \n",
    "        # cosine of lists\n",
    "        dd = create_pair_distances(v1,v2)\n",
    "        np.save(dd_name,dd)\n",
    "    print('done')\n",
    "    return dd\n",
    "\n",
    "def write_to_file(model_name,pairwise_data):\n",
    "    print('writing',model_name)\n",
    "    f = f'{output}/{model_name}-pairwise.tsv.gz'\n",
    "    if os.path.exists(f):\n",
    "        print('Already done',f)\n",
    "    else:\n",
    "        fo = gzip.open(f,'w')\n",
    "        fo.write(\"ebi\\tefo\\tscore\\n\".encode('utf-8'))\n",
    "        ebi_efo_list = ebi_df['full_id']\n",
    "        efo_list = efo_df['efo_id']\n",
    "        for i in range(0,len(ebi_efo_list)):\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "            # write to file\n",
    "            mCount=0\n",
    "            for j in range(i,len(efo_list)):\n",
    "                if i != j:\n",
    "                    #print(ids[i],ids[j],1-pws[mCount])\n",
    "                    score = 1-pairwise_data[i][j]\n",
    "                    fo.write(f\"{ebi_efo_list[i]}\\t{efo_list[j]}\\t{score}\\n\".encode('utf-8'))\n",
    "                    mCount+=1\n",
    "                \n",
    "def get_top(model,pairwise_data):\n",
    "    count=0\n",
    "    dis_results=[]\n",
    "    efo_map = []\n",
    "    cosine_results = []\n",
    "    manual_pos_results = []\n",
    "    for manual_efo in ebi_df['full_id']:\n",
    "        predicted_efo = None\n",
    "        #min_val = 0\n",
    "        min_val=None\n",
    "        manual_dis_loc=None\n",
    "        nx_val=None\n",
    "        cosine_val=None\n",
    "        \n",
    "        #skip encodings with just zeros\n",
    "        if np.count_nonzero(ebi_df.iloc[count][model])>0:\n",
    "            #print('Empty encoding',ebi_df.iloc[count][model])\n",
    "            \n",
    "            # find the EFO term with minumum distance\n",
    "            min_dis = np.nanargmin(pairwise_data[count])\n",
    "            min_val = np.nanmin(pairwise_data[count])\n",
    "            cosine_val = 1-min_val\n",
    "\n",
    "            predicted_efo = efo_df.iloc[min_dis]['efo_id']\n",
    "            #efo_map.append(predicted_efo)\n",
    "\n",
    "            # find the location of the 'correct' EFO term and get ordered position \n",
    "            manual_loc = efo_df[efo_df['efo_id'] == manual_efo].index[0]\n",
    "            manual_dis = pairwise_data[count][manual_loc]\n",
    "            \n",
    "            #print(manual_dis)\n",
    "            # create sorted list of cosines to find position of manual mapped EFO\n",
    "            # deal with nan too\n",
    "            sorted_dis = sorted([x for x in pairwise_data[count] if str(x) != 'nan'])\n",
    "            manual_dis_loc = sorted_dis.index(manual_dis)\n",
    "            \n",
    "\n",
    "            #run nxontology similarity\n",
    "            res = similarity = efo_nx.similarity(manual_efo,predicted_efo).results()\n",
    "            nx_val = res[nxontology_measure]\n",
    "            \n",
    "        manual_pos_results.append(manual_dis_loc)\n",
    "        dis_results.append(nx_val)    \n",
    "        cosine_results.append(cosine_val)\n",
    "        efo_map.append(predicted_efo)\n",
    "        count+=1\n",
    "        \n",
    "    ebi_df[f'{model}-nx']=dis_results\n",
    "    ebi_df[f'{model}-efo']=efo_map\n",
    "    ebi_df[f'{model}-cosine']=cosine_results\n",
    "    ebi_df[f'{model}-rank']=manual_pos_results\n",
    "    #print(ebi_df.head())\n",
    "    print(model,'greater than 0.9:',ebi_df[ebi_df[f'{model}-nx']>0.9].shape)\n",
    "    \n",
    "    #plot histogram of distances\n",
    "    sns_plot = sns.displot(ebi_df, x=f\"{model}-nx\",kde=True)\n",
    "    sns_plot.savefig(f\"{output}/{model}-{nxontology_measure}-nx.pdf\")\n",
    "    \n",
    "    #plot correlation between cosine and nxontolgy\n",
    "    sns_rel = sns.relplot(data=ebi_df, x=f'{model}-nx', y=f'{model}-cosine')\n",
    "    sns_rel.savefig(f\"{output}/{model}-nx-vs-cosine.pdf\")\n",
    "    \n",
    "    #plot histogram of correct EFO location\n",
    "    sns_plot = sns.displot(ebi_df, x=f\"{model}-rank\", kind='kde', cut=0, palette=pallete, height=6, cumulative=True,common_norm=False)\n",
    "    sns_plot.savefig(f\"{output}/{model}-rank.pdf\")\n",
    "\n",
    "#dd = run_pairs('BioSentVec')\n",
    "#get_top('BioSentVec',dd)\n",
    "#for m in modelData:\n",
    "#    dd = run_pairs(m['name'])\n",
    "#    get_top(m['name'],dd)    \n",
    "\n",
    "#print(ebi_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#dd = run_pairs('BioSentVec')\n",
    "#get_top('BioSentVec',dd)\n",
    "\n",
    "#get_top('BioSentVec',dd)\n",
    "f = '{output}/ebi-df2.csv.gz'\n",
    "if os.path.exists(f):\n",
    "    print('Done, reading',f)\n",
    "    ebi_df = pd.read_csv(f)\n",
    "else:\n",
    "    for m in modelData:\n",
    "        print(m['name'])\n",
    "        if m['name'] in ebi_df:\n",
    "            dd = run_pairs(m['name'])\n",
    "            #get_top(m['name'],dd)   \n",
    "            write_to_file(model_name=m['name'],pairwise_data=dd) \n",
    "    ebi_df.to_csv(f,compression='gzip')\n",
    "            \n",
    "    \n",
    "\n",
    "print(ebi_df.head())\n",
    "print(ebi_df.describe())\n",
    "print(ebi_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ontoma \n",
    "# print(otmap.find_term('Vascular disorders of intestine'))\n",
    "# think this is just using zooma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zooma using web app\n",
    "# ran the web app using filtered list of terms\n",
    "# Configure Data Sources - Don't search in any datasources checked\n",
    "# Configure Ontology Sources - EFO\n",
    "# https://www.ebi.ac.uk/spot/zooma\n",
    "\n",
    "#zooma_df = pd.read_csv('data/zooma.tsv',sep='\\t')\n",
    "#zooma_df['zooma_efo'] = zooma_df['ONTOLOGY(S)']+zooma_df['ONTOLOGY TERM(S)']\n",
    "#zooma_df.drop_duplicates(subset=['zooma_efo'],inplace=True)\n",
    "#print(zooma_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zooma using API\n",
    "def run_zooma(text):\n",
    "    zooma_api = 'https://www.ebi.ac.uk/spot/zooma/v2/api/services/annotate'\n",
    "    payload = {\n",
    "        'propertyValue':text,\n",
    "        'filter':'required:[none],ontologies:[efo]'\n",
    "    }\n",
    "    res = requests.get(zooma_api,params=payload).json()\n",
    "    if res:\n",
    "        #print(text,res[0]['semanticTags'])\n",
    "        return res[0]['semanticTags'][0]\n",
    "    else:\n",
    "        return 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# takes around 3 minutes for 1,000\n",
    "f='{output}/ebi-zooma-api.tsv'\n",
    "if os.path.exists(f):\n",
    "    ebi_df_zooma = pd.read_csv(f,sep='\\t')\n",
    "else:\n",
    "    ebi_df_zooma = ebi_df\n",
    "    ebi_df_zooma['zooma_api'] = ebi_df_zooma['query'].apply(lambda x:run_zooma(x))\n",
    "    ebi_df_zooma.to_csv('{output}/ebi-zooma-api.tsv',sep='\\t',index=False)\n",
    "print(ebi_df_zooma.head())\n",
    "print(ebi_df_zooma.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(zooma_df.head())\n",
    "\n",
    "# merge with ebi file\n",
    "#m = pd.merge(zooma_df,ebi_df,left_on='PROPERTY VALUE',right_on='query')\n",
    "#m.drop_duplicates(inplace=True)\n",
    "#print(m.head())\n",
    "#print(m.shape)\n",
    "\n",
    "dis_results=[]\n",
    "efo_results=[]\n",
    "for i, row in ebi_df_zooma.iterrows():\n",
    "    try:\n",
    "        res = similarity = efo_nx.similarity(row['zooma_api'],row['full_id']).results()\n",
    "        dis_results.append(res[nxontology_measure])\n",
    "    except:\n",
    "        dis_results.append(0)\n",
    "        \n",
    "print(len(dis_results))\n",
    "ebi_df['Zooma-nx'] = dis_results\n",
    "ebi_df['Zooma-efo'] = ebi_df_zooma['zooma_api']\n",
    "print(ebi_df[ebi_df['Zooma-nx']>0.9].shape)\n",
    "ebi_df.to_csv('{output}/ebi-nx.tsv',sep='\\t',index=False)\n",
    "sns.displot(ebi_df, x=\"Zooma-nx\",kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT-EFO\n",
    "\n",
    "def bert_efo():\n",
    "    bef_df = pd.read_csv('data/bluebert_efo_mapping.csv')\n",
    "    bef_df.rename(columns={'efo_id':'BERT-EFO-efo'},inplace=True)\n",
    "    print(bef_df.head())\n",
    "    print(bef_df.shape)\n",
    "\n",
    "    # merge with ebi_df\n",
    "    ebi_df_merge = pd.merge(ebi_df,bef_df,left_on='query',right_on='ukbb_trait')\n",
    "    print(ebi_df_merge.head())\n",
    "\n",
    "    dis_results=[]\n",
    "    name = 'BERT-EFO-nx'\n",
    "    for i, row in ebi_df_merge.iterrows():\n",
    "        res = similarity = efo_nx.similarity(row['BERT-EFO-efo'],row['full_id']).results()\n",
    "        dis_results.append(res[nxontology_measure])\n",
    "\n",
    "\n",
    "    print(len(dis_results))\n",
    "    ebi_df_merge[name] = dis_results\n",
    "    print(ebi_df_merge.head())\n",
    "    print(ebi_df_merge[ebi_df_merge['BERT-EFO-nx']>0.9].shape)\n",
    "    ebi_df_merge.to_csv('{output}/ebi-nx.tsv',sep='\\t',index=False)\n",
    "    sns.displot(ebi_df_merge, x=name,kde=True)\n",
    "    return ebi_df_merge\n",
    "ebi_df_merge=bert_efo()\n",
    "print(ebi_df_merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebi_df_merge.shape)\n",
    "def add_bert_ranks():\n",
    "    df = pd.read_csv('data/bluebert_efo_rankings.csv')\n",
    "    print(df.head())\n",
    "    m = pd.merge(ebi_df_merge,df[['ukbb_trait','ranking']],left_on='ukbb_trait',right_on='ukbb_trait')\n",
    "    m.rename(columns={'ranking':'BERT-EFO-rank'},inplace=True)\n",
    "    print(m.head())\n",
    "    return m\n",
    "ebi_df_merge = add_bert_ranks()\n",
    "print(ebi_df_merge.shape)\n",
    "ebi_df_merge.drop_duplicates(subset=['query','full_id'],inplace=True)\n",
    "print(ebi_df_merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the methods\n",
    "# which values does BioSentVec map but zooma does not?\n",
    "\n",
    "#bb1 = ebi_df_merge[(ebi_df['BioSentVec-nx']==1) & (ebi_df_merge['Zooma-nx']<0.8)]\n",
    "#print(bb1.shape)\n",
    "\n",
    "#bb2 = ebi_df_merge[(ebi_df['Zooma-nx']==1) & (ebi_df_merge['BioSentVec-nx']<0.8)]\n",
    "#print(bb2[['query','MAPPED_TERM_LABEL','full_id','BioSentVec-nx','BioSentVec-efo']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebi_df_merge[ebi_df_merge['BERT-EFO-nx']==1].shape)\n",
    "print(ebi_df_merge[ebi_df_merge['BioSentVec-nx']==1].shape)\n",
    "print(ebi_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt data for plots\n",
    "#ebi_df_merge = ebi_df\n",
    "#print(ebi_df_merge.head())\n",
    "\n",
    "print(ebi_df_merge.describe())\n",
    "print(ebi_df_merge.shape)\n",
    "nx_list = ['BioSentVec-nx','BlueBERT-nx','BioBERT-nx','Zooma-nx','BERT-EFO-nx','GUSE-nx']\n",
    "\n",
    "#ebi_df_merge.reset_index(inplace=True)\n",
    "print(ebi_df_merge.head())\n",
    "ebi_df_melt = pd.melt(ebi_df_merge, id_vars=['query'], value_vars=nx_list)\n",
    "#ebi_df_melt = pd.melt(ebi_df_merge, id_vars=['query'], value_vars=['BioSentVec-nx','BlueBERT-nx','BioBERT-nx','Zooma-nx'])\n",
    "ebi_df_melt.rename(columns={'variable':'Model'},inplace=True)\n",
    "#print(ebi_df_melt.head())\n",
    "\n",
    "\n",
    "# violin plot\n",
    "#ax = sns.violinplot(x=\"variable\", y=\"value\", inner='quartile', data=ebi_df_melt, cut=0)\n",
    "#ax.set_title('EFO distance', fontsize=16);\n",
    "#fig = ax.get_figure()\n",
    "#fig.savefig(f\"output/all-nx.pdf\")\n",
    "\n",
    "plot_kind=\"kde\"\n",
    "ax = sns.displot(x=\"value\", hue=\"Model\", data=ebi_df_melt, kind=plot_kind, cut=0, palette=pallete, height=6)\n",
    "#ax = sns.displot(x=\"value\", hue=\"Model\", data=ebi_df_melt, kind=plot_kind, palette=pallete, height=6,kde=True,stat='density')\n",
    "ax.set(xlabel=f'nxontology score ({nxontology_measure})', ylabel=plot_kind)\n",
    "ax.savefig(f\"{output}/all-nx-{plot_kind}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustermap\n",
    "#g = sns.clustermap(ebi_df_merge[nx_list])\n",
    "#g.savefig('{output}/clustermap.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas profiling\n",
    "profile = ProfileReport(ebi_df_merge, title=\"Pandas Profiling Report\")\n",
    "#profile.to_widgets()\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general metrics\n",
    "\n",
    "def describe_and_plot(df,col_list,name):\n",
    "    describe_df = df[col_list].describe()\n",
    "    describe_df.drop(['count','max'],inplace=True)\n",
    "    describe_df.reset_index(inplace=True)\n",
    "    print(describe_df)\n",
    "    describe_df_melt = pd.melt(describe_df, id_vars = ['index'])\n",
    "\n",
    "    g = sns.catplot(\n",
    "        data=describe_df_melt, kind=\"bar\",\n",
    "        x=\"index\", y=\"value\", hue=\"variable\",\n",
    "         palette=pallete, height=6\n",
    "    )\n",
    "    g.despine(left=True)\n",
    "    g.set_axis_labels(\"\", name)\n",
    "    g.legend.set_title(\"\")\n",
    "    g.savefig(f'{output}/{name}-describe.pdf')\n",
    "    \n",
    "describe_and_plot(ebi_df_merge,nx_list,'nxontology')\n",
    "ranking_list = ['BioSentVec-rank','BlueBERT-rank','BioBERT-rank','BERT-EFO-rank','GUSE-rank']\n",
    "describe_and_plot(ebi_df_merge,ranking_list,'ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebi_df_ranking_melt = pd.melt(ebi_df_merge, id_vars=['query'], value_vars=ranking_list)\n",
    "ebi_df_ranking_melt.rename(columns={'variable':'Model'},inplace=True)\n",
    "print(ebi_df_ranking_melt.head())\n",
    "\n",
    "# violin\n",
    "#ax = sns.violinplot(x=\"variable\", y=\"value\", inner='quartile', data=ebi_df_ranking_melt, cut=0)\n",
    "#ax.set_title('EFO ranking position', fontsize=16);\n",
    "#ax.set_yscale(\"log\")\n",
    "#ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "#fig = ax.get_figure()\n",
    "\n",
    "# density\n",
    "ax = sns.displot(x=\"value\", hue=\"Model\", data=ebi_df_ranking_melt, kind='kde', cut=0, palette=pallete, height=6, cumulative=True,common_norm=False)\n",
    "#ax = sns.kdeplot(x=\"value\", hue=\"Model\", data=ebi_df_ranking_melt, cut=0, palette=pallete, cumulative=True)\n",
    "#ax = sns.displot(x=\"value\", hue=\"Model\", data=ebi_df_melt, kind=plot_kind, palette=pallete, height=6,kde=True,stat='density')\n",
    "#ax.set(xlabel=f'ranking distance', ylabel=plot_kind).set(xscale ='log')\n",
    "ax.set(xlabel=f'ranking distance', ylabel=plot_kind)\n",
    "#ax.set_xscale(\"log\")\n",
    "ax.savefig(f\"{output}/all-ranking-kde.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check some things\n",
    "# number of nx value of 1 for each model\n",
    "#print(modelData)\n",
    "#print(ebi_df_merge.shape)\n",
    "#print(ebi_df_merge.head())\n",
    "ebi_df_merge = ebi_df_merge.drop_duplicates(subset=['query','id'])\n",
    "print(ebi_df_merge.shape)\n",
    "topSummary = []\n",
    "for m in modelData:\n",
    "    mName = f\"{m['name']}-nx\"\n",
    "    if mName in ebi_df_merge:\n",
    "        ##print(m)\n",
    "        nx1 = ebi_df_merge[ebi_df_merge[mName]>0.9].shape[0]/ebi_df.shape[0]\n",
    "        if f\"{m['name']}-rank\" in ebi_df_merge:\n",
    "            ranking10 = ebi_df_merge[ebi_df_merge[f\"{m['name']}-rank\"]<10].shape[0]/ebi_df.shape[0]\n",
    "        else:\n",
    "            ranking10 = None\n",
    "        topSummary.append({'name':m['name'],'nx1':nx1,'ranking10':ranking10})\n",
    "    else:\n",
    "        print(m['name'],'missing')\n",
    "print(topSummary)\n",
    "df = pd.DataFrame(topSummary)\n",
    "print(df.head())\n",
    "\n",
    "def plot_summary(df):\n",
    "    df_melt = pd.melt(df, id_vars = ['name'])\n",
    "    print(df_melt)\n",
    "\n",
    "    g = sns.catplot(\n",
    "        data=df_melt, kind=\"bar\",\n",
    "        x=\"variable\", y=\"value\", hue=\"name\",\n",
    "            palette=pallete, height=6\n",
    "    )\n",
    "    g.despine(left=True)\n",
    "    #g.set_axis_labels(\"\", name)\n",
    "    g.legend.set_title(\"\")\n",
    "    g.savefig(f'{output}/nx-ranking-summary.pdf')\n",
    "plot_summary(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cases for each model where all other models don't map well\n",
    "#print(modelData)\n",
    "\n",
    "for i in modelData:\n",
    "    fName = f\"{i['name']}-nx\"\n",
    "    if fName in ebi_df_merge:\n",
    "        d = ebi_df_merge[ebi_df_merge[fName]>0.9]\n",
    "        for j in modelData:\n",
    "            if i != j:\n",
    "                # find hits not matched with other models\n",
    "                fNameFilt = f\"{j['name']}-nx\"\n",
    "                d = d[d[fNameFilt]<0.5]        \n",
    "    else:\n",
    "        print(m['name'], 'not in df')\n",
    "    print(fName,d.shape[0],'\\n',d['query'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cases where no model mapped correctly\n",
    "d = ebi_df_merge\n",
    "cols = ['query','full_id']\n",
    "for i in modelData:\n",
    "    fName = f\"{i['name']}-nx\"\n",
    "    d = d[d[fName]<1]\n",
    "    cols.append(f\"{i['name']}-nx\")\n",
    "    cols.append(f\"{i['name']}-efo\")\n",
    "print(d.shape[0],'\\n',d[cols],'\\n')   \n",
    "\n",
    "# nx distances for each model for missing values, i.e. which one was closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "top_x = 100\n",
    "\n",
    "def filter_paiwise_file(model_name):\n",
    "    print('filter_pairwise_file',model_name)\n",
    "    f = f\"{output}/{model_name}-pairwise-filter.tsv.gz\"\n",
    "    if os.path.exists(f):\n",
    "        print('Already done',model_name)\n",
    "        return\n",
    "    else:\n",
    "        try:\n",
    "            df = pd.read_csv(f\"{output}/{model_name}-pairwise.tsv.gz\",sep='\\t')\n",
    "            print(df.shape)\n",
    "            df = df.sort_values(by=['score'],ascending=False).groupby('ebi').head(top_x)\n",
    "            print(df.shape)\n",
    "            df.sort_values(by=['ebi','score'],ascending=False).to_csv(f,sep='\\t',index=False,compression='gzip')\n",
    "        except:\n",
    "            print('Error',model_name)\n",
    "            return\n",
    "\n",
    "def filter_bert():\n",
    "    df = pd.read_csv(f\"data/efo_mk1_inference.csv.gz\")\n",
    "    df_top = df.sort_values(by=['score']).groupby('text_1').head(100)\n",
    "    df_top = pd.merge(df_top,ebi_df[['query','full_id']],left_on='text_1',right_on='query')\n",
    "    df_top.rename(columns={'full_id':'ebi'},inplace=True)\n",
    "    df_top.drop('query',axis=1,inplace=True)\n",
    "\n",
    "    #map to predicted EFO\n",
    "    df_top = pd.merge(df_top,efo_node_df,left_on='text_2',right_on='efo_label')\n",
    "    df_top.rename(columns={'efo_id':'efo'},inplace=True)\n",
    "    df_top.drop('efo_label',axis=1,inplace=True)\n",
    "    print(df_top.head())\n",
    "    df_top[['ebi','efo','score']].sort_values(by=['ebi','score']).to_csv(f'{output}/BERT-EFO-pairwise-filter.tsv.gz',index=False,compression='gzip',sep='\\t')\n",
    "    print(df_top.head())\n",
    "\n",
    "def get_top_using_pairwise_file(model_name,top_num):\n",
    "    f = f\"{output}/{model_name}-top-{top_num}.tsv\"\n",
    "    if os.path.exists(f):\n",
    "        print('Top done',model_name)\n",
    "    else:\n",
    "        print('Reading',model_name)\n",
    "        try:\n",
    "            df = pd.read_csv(f\"{output}/{model_name}-pairwise-filter.tsv.gz\",sep='\\t')\n",
    "        except:\n",
    "            print('Data do not exist for',model_name)\n",
    "            return\n",
    "        print(df.head())\n",
    "        print(df.shape)\n",
    "        top_res = []\n",
    "        manual_efos = list(ebi_df['full_id'])\n",
    "        for i in range(0,len(manual_efos)):\n",
    "        #for i in range(0,10):\n",
    "            manual_efo = manual_efos[i]\n",
    "           # print(i,manual_efo)\n",
    "            efo_predictions = df[df['ebi']==manual_efo].head(n=top_num)[['efo','score']]\n",
    "            #end = time.time()\n",
    "            #print(end-start)\n",
    "            #print(efo_predictions)\n",
    "            # run nxontolog for each\n",
    "            for i,row in efo_predictions.iterrows():\n",
    "                predicted_efo = row['efo']\n",
    "                score = row['score']\n",
    "                #print(predicted_efo,score)\n",
    "                res = similarity = efo_nx.similarity(manual_efo,predicted_efo).results()\n",
    "                nx_val = res[nxontology_measure]\n",
    "                top_res.append({'manual':manual_efo,'predicted':predicted_efo,'score':score,'nx':nx_val})  \n",
    "                #print(f\"manual: {manual_efo} predicted: {predicted_efo} score: {score} nx: {nx_val}\")\n",
    "        res_df = pd.DataFrame(top_res)\n",
    "        res_df.to_csv(f,index=False)\n",
    "\n",
    "#for m in modelData:\n",
    "#    filter_paiwise_file(model_name=m['name'])\n",
    "#filter_bert()\n",
    "for m in modelData:\n",
    "    get_top_using_pairwise_file(model_name=m['name'],top_num=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate weighted average\n",
    "\n",
    "def calc_weighted_average(model_name,top_num,mapping_types):\n",
    "    f = f\"{output}/{model_name}-top-100.tsv\"\n",
    "    print(f)\n",
    "    res = []\n",
    "    try:\n",
    "        df = pd.read_csv(f,sep=',')\n",
    "        #print(df.head())\n",
    "    except:\n",
    "        print('Data do not exist for',model_name)\n",
    "        return\n",
    "    manual_efos = list(ebi_df['full_id'])\n",
    "    for i in range(0,len(manual_efos)):\n",
    "        manual_efo = manual_efos[i]\n",
    "        #filter on type\n",
    "        mapping_type = ebi_df[ebi_df['full_id']==manual_efo]['MAPPING_TYPE'].values[0]\n",
    "        #print(mapping_type)\n",
    "        if mapping_type in mapping_types:\n",
    "            #print(i,manual_efo)\n",
    "            nx_scores = list(df[df['manual']==manual_efo].head(n=top_num)['nx'])\n",
    "            weights = list(reversed(range(1,(len(nx_scores)+1))))\n",
    "            weighted_avg = round(np.average( nx_scores, weights = weights),3)\n",
    "            res.append(weighted_avg)\n",
    "    print(len(res))\n",
    "    return res\n",
    "\n",
    "#res = calc_weighted_average('BioSentVec',5)\n",
    "\n",
    "all_res = {}\n",
    "#top_nums=[5]\n",
    "top_nums=[1,2,5,10,20,50,100]\n",
    "\n",
    "def run(mapping_types,mapping_name):\n",
    "    for top_num in top_nums:\n",
    "        for m in modelData:\n",
    "            res = calc_weighted_average(m['name'],top_num,mapping_types)\n",
    "            if res is not None:\n",
    "                all_res[m['name']]=res\n",
    "\n",
    "        df = pd.DataFrame(all_res)\n",
    "        df['efo'] = ebi_df['full_id']\n",
    "        #print(df.head())\n",
    "        df_melt = pd.melt(df, id_vars=['efo'])\n",
    "        df_melt.rename(columns={'variable':'Model'},inplace=True)\n",
    "        #print(df_melt.head())\n",
    "        #ax = sns.displot(x=\"value\", hue=\"Model\", data=df_melt, kind='kde', cut=0, palette=pallete, height=6, cumulative=True,common_norm=False)\n",
    "        ax = sns.displot(x=\"value\", hue=\"Model\", data=df_melt, kind='kde', cut=0, palette=pallete, height=6,common_norm=False)\n",
    "        ax.set(xlabel=f'Weighted average of nx', ylabel='kde')\n",
    "        #ax.set_xscale(\"log\")\n",
    "        ax.savefig(f\"{output}outp/weighted-average-nx-{top_num}-{mapping_name}.pdf\")\n",
    "\n",
    "run(mapping_types=['Exact','Broad','Narrow'],mapping_name='all')\n",
    "run(mapping_types=['Exact'],mapping_name='exact')\n",
    "run(mapping_types=['Broad','Narrow'],mapping_name='broad-narrow')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('Vectology': conda)",
   "language": "python",
   "name": "python37764bitvectologycondabddc1d88bf5b4c4f8d962b6bae51eabd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}